# -*- coding: utf-8 -*-
"""Time series analysis agent

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ZTfYPQZXObgxqk3hawGu9Sm33EjJX2xA
"""

# Install Google Generative AI SDK
!pip install -q google-generativeai python-dotenv

print("✅ Dependencies installed successfully!")

# ==== Imports ====
from __future__ import annotations
import json
import re
import io
import sys
import traceback
from typing import Any, Dict, Optional
from datetime import datetime, timedelta
import os

# Data manipulation
import pandas as pd
import numpy as np

# Visualization
import matplotlib.pyplot as plt
import seaborn as sns

# Set visualization style
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (12, 6)

# Gemini API
import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold

# For Google Colab
from google.colab import userdata
from IPython.display import HTML, display

print("✅ All imports successful!")

# Get API key from Colab secrets
try:
    GEMINI_API_KEY = userdata.get('GEMINI_API_KEY')
    genai.configure(api_key=GEMINI_API_KEY)
    print("✅ Gemini API configured successfully!")

    # List available models
    print("\n📋 Available Gemini models:")
    available_models = []
    for model in genai.list_models():
        if 'generateContent' in model.supported_generation_methods:
            available_models.append(model.name)
            print(f"  - {model.name}")

    # Suggest a model
    if available_models:
        # Prefer flash models for speed
        flash_models = [m for m in available_models if 'flash' in m.lower()]
        if flash_models:
            recommended_model = flash_models[0].replace('models/', '')
            print(f"\n💡 Recommended model: {recommended_model}")
        else:
            recommended_model = available_models[0].replace('models/', '')
            print(f"\n💡 Available model: {recommended_model}")

except Exception as e:
    print(f"❌ Error: {e}")
    print("Please add GEMINI_API_KEY to Colab secrets (see instructions above)")

from google.colab import files

# Upload your CSV file
uploaded = files.upload()

# Get the filename
csv_filename = list(uploaded.keys())[0]
print(f"✅ Uploaded: {csv_filename}")

# Load the CSV
df_original = pd.read_csv(csv_filename)

# Clean column names (remove leading/trailing spaces)
df_original.columns = df_original.columns.str.strip()

# Make a working copy
df = df_original.copy()

# Parse dates and set as index
df['Order_Date'] = pd.to_datetime(df['Order_Date'], format='%m-%d-%y', errors='coerce')

# Display basic info
print(f"✅ Loaded {len(df):,} rows")
print(f"📅 Date range: {df['Order_Date'].min()} to {df['Order_Date'].max()}")
print(f"\n📊 Dataset Info:")
print(df.info())
print(f"\n🔍 First 5 rows:")
df.head()

def build_schema_block(df: pd.DataFrame, sample_size: int = 5) -> str:
    """
    Generate a schema description for the LLM prompt.
    Includes column info, data types, sample values, and available filters.
    """
    schema_parts = []

    # Dataset overview
    schema_parts.append(f"Dataset: E-Commerce Transactions")
    schema_parts.append(f"Total Rows: {len(df):,}")
    schema_parts.append(f"Date Range: {df['Order_Date'].min().strftime('%Y-%m-%d')} to {df['Order_Date'].max().strftime('%Y-%m-%d')}")
    schema_parts.append("\n--- COLUMN SCHEMA ---")

    # Column details
    for col in df.columns:
        dtype = str(df[col].dtype)
        unique_count = df[col].nunique()

        if col == 'Order_Date':
            schema_parts.append(f"  {col} (datetime64): Order timestamp")
        elif col == 'Order_ID':
            schema_parts.append(f"  {col} (int): Unique order identifier")
        elif col in ['Customer_Name', 'City', 'State', 'Region', 'Country']:
            examples = df[col].dropna().unique()[:3].tolist()
            schema_parts.append(f"  {col} (string): {unique_count} unique values. Examples: {examples}")
        elif col in ['Category', 'Sub_Category', 'Product_Name']:
            examples = df[col].dropna().unique()[:3].tolist()
            schema_parts.append(f"  {col} (string): {unique_count} unique values. Examples: {examples}")
        elif col in ['Quantity', 'Unit_Price', 'Revenue', 'Profit']:
            min_val = df[col].min()
            max_val = df[col].max()
            mean_val = df[col].mean()
            schema_parts.append(f"  {col} (float): Range [{min_val:.2f}, {max_val:.2f}], Mean: {mean_val:.2f}")

    # Available categorical values
    schema_parts.append("\n--- AVAILABLE FILTER VALUES ---")
    schema_parts.append(f"Regions: {df['Region'].unique().tolist()}")
    schema_parts.append(f"Categories: {df['Category'].unique().tolist()}")
    schema_parts.append(f"Top 10 Products: {df['Product_Name'].value_counts().head(10).index.tolist()}")

    # Sample rows
    schema_parts.append(f"\n--- SAMPLE DATA (first {sample_size} rows) ---")
    sample_df = df.head(sample_size)[['Order_Date', 'Category', 'Product_Name', 'Region', 'Revenue', 'Profit']]
    schema_parts.append(sample_df.to_string(index=False))

    return "\n".join(schema_parts)

# Generate and display schema
schema = build_schema_block(df)
print("\n📋 Generated Schema:\n")
print(schema)

def get_date_range(df: pd.DataFrame, start: str, end: str) -> pd.DataFrame:
    """Filter DataFrame by date range (inclusive)."""
    return df[(df['Order_Date'] >= start) & (df['Order_Date'] <= end)]

def get_quarter_data(df: pd.DataFrame, year: int, quarter: int) -> pd.DataFrame:
    """Extract specific quarter (1-4) from a given year."""
    quarter_start = pd.Timestamp(year=year, month=(quarter-1)*3+1, day=1)
    quarter_end = (quarter_start + pd.DateOffset(months=3)) - pd.Timedelta(days=1)
    return df[(df['Order_Date'] >= quarter_start) & (df['Order_Date'] <= quarter_end)]

def calculate_profit_margin(df: pd.DataFrame) -> pd.Series:
    """Calculate profit margin percentage (Profit/Revenue * 100)."""
    return (df['Profit'] / df['Revenue'] * 100).replace([np.inf, -np.inf], 0)

def get_top_n(df: pd.DataFrame, column: str, metric: str = 'Revenue', n: int = 10) -> pd.DataFrame:
    """Get top N items by a metric, grouped by a column."""
    return df.groupby(column)[metric].sum().nlargest(n).reset_index()

def detect_outliers(series: pd.Series, threshold: float = 3.0) -> pd.Series:
    """Detect outliers using z-score method."""
    z_scores = np.abs((series - series.mean()) / series.std())
    return z_scores > threshold

print("✅ Helper functions defined!")

def print_html(content: str, title: str = "") -> None:
    """Display formatted HTML output in Colab."""
    html = f"""
    <div style="border:1px solid #3B82F6; border-left:6px solid #3B82F6; background:#EFF6FF;
                border-radius:6px; padding:16px; margin:10px 0;
                font-family:system-ui,-apple-system,sans-serif;">
        <h4 style="margin-top:0; color:#1E40AF;">{title}</h4>
        <pre style="white-space: pre-wrap; word-wrap: break-word; color:#1E3A8A;">{content}</pre>
    </div>
    """
    display(HTML(html))

print("✅ Display helper ready!")

PROMPT = """You are a senior data analyst specializing in time series analysis. PLAN BY WRITING PYTHON CODE USING PANDAS.

  Dataset Schema & Samples:
  {schema_block}

  Execution Environment (already imported/provided):
  - Variables: df (pandas DataFrame with DatetimeIndex), user_request (str)
  - Modules: pandas as pd, numpy as np, datetime, matplotlib.pyplot as plt, seaborn as sns
  - Helper Functions:
    * get_date_range(df, start, end) -> DataFrame
    * get_quarter_data(df, year, quarter) -> DataFrame
    * calculate_profit_margin(df) -> Series
    * get_top_n(df, column, metric, n) -> DataFrame
    * detect_outliers(series, threshold) -> Series (boolean mask)

  PLANNING RULES (critical):
  - Derive ALL filters/parameters from user_request. Do NOT hard-code values unless specified.
  - Use pandas operations: .query(), .loc[], .groupby(), .resample(), .rolling(), etc.
  - For date filtering, use datetime operations on df['Order_Date']
  - Be conservative: if intent is ambiguous, provide exploratory analysis
  - When user asks for charts/plots/graphs, ALWAYS create visualizations using matplotlib/seaborn

  VISUALIZATION GUIDELINES:
  - When user mentions "chart", "plot", "graph", "visualize", "show", generate visualization code
  - Use plt.figure(figsize=(12, 6)) for good readability
  - Add proper titles, labels, and legends
  - For multiple categories, use different colors/lines
  - Use plt.xticks(rotation=45) for date labels
  - Call plt.tight_layout() before plt.show()
  - Always include plt.show() at the end to display the plot

  TIME SERIES OPERATIONS:
  - Filtering: df[df['Order_Date'].between(start, end)]
  - Resampling: df.set_index('Order_Date').resample('ME')['Revenue'].sum()  # Use 'ME' not 'M'
  - Rolling windows: df['Revenue'].rolling(window=7).mean()
  - Period comparison: Compare same periods across years
  - Trend analysis: Calculate growth rates, moving averages

  HUMAN RESPONSE REQUIREMENT (mandatory):
  - MUST set variable `answer_text` (str): A clear, business-friendly summary (2-4 sentences)
  - This is the primary user-facing message - make it insightful and actionable
  - Optionally set `answer_json` (dict/list) or `answer_df` (DataFrame) for structured data

  SELF-CORRECTION & VALIDATION:
  - Always set `STATUS` variable to one of:
    * "success": Analysis completed successfully
    * "no_data": No records match the filters → suggest alternative filters
    * "invalid_date": Date parsing failed → specify correct format needed
    * "invalid_filter": Unknown category/region/product → list available options
    * "ambiguous_request": Unclear intent → ask clarifying question
    * "error": Unexpected error → include error details

  ERROR HANDLING:
  - Wrap main logic in try/except
  - Check for empty results: if filtered_df.empty: STATUS = "no_data"
  - Validate inputs: Check if category exists before filtering
  - Handle edge cases: division by zero, missing dates, invalid ranges

  OUTPUT CONTRACT:
  - Return ONLY executable Python between these tags:
    <execute_python>
    # your pandas code here
    </execute_python>

  CODE STRUCTURE:
  1) Parse user intent from user_request (extract dates, categories, metrics)
  2) Validate inputs (check if values exist in dataset)
  3) Apply filters using pandas operations
  4) Perform time series analysis (groupby, resample, aggregate)
  5) Calculate insights (trends, comparisons, statistics)
  6) CREATE VISUALIZATIONS if requested (charts, plots, graphs)
  7) Set answer_text, STATUS, and optional answer_json/answer_df
  8) Print diagnostic logs to stdout (for debugging)

  EXAMPLE PATTERNS:

  # Filtering by date range and category
  filtered = df[
      (df['Order_Date'] >= '2024-01-01') &
      (df['Order_Date'] <= '2024-03-31') &
      (df['Category'] == 'Electronics')
  ]

  # Monthly revenue trend with visualization
  monthly = df.set_index('Order_Date').resample('ME')['Revenue'].sum()
  plt.figure(figsize=(12, 6))
  monthly.plot(kind='line', marker='o')
  plt.title('Monthly Revenue Trend')
  plt.xlabel('Month')
  plt.ylabel('Revenue ($)')
  plt.xticks(rotation=45)
  plt.tight_layout()
  plt.show()

  # Multiple categories line chart
  pivot_data = df.groupby([pd.Grouper(key='Order_Date', freq='ME'), 'Category'])['Revenue'].sum().reset_index()
  pivot_wide = pivot_data.pivot(index='Order_Date', columns='Category', values='Revenue')
  plt.figure(figsize=(14, 7))
  for category in pivot_wide.columns:
      plt.plot(pivot_wide.index, pivot_wide[category], marker='o', label=category, linewidth=2)
  plt.title('Monthly Revenue Trend by Category')
  plt.xlabel('Month')
  plt.ylabel('Revenue ($)')
  plt.legend(title='Category', bbox_to_anchor=(1.05, 1), loc='upper left')
  plt.grid(True, alpha=0.3)
  plt.xticks(rotation=45)
  plt.tight_layout()
  plt.show()

  # 7-day rolling average
  df_sorted = df.sort_values('Order_Date')
  df_sorted['Revenue_MA7'] = df_sorted['Revenue'].rolling(window=7).mean()

  # Top products by profit
  top_products = df.groupby('Product_Name')['Profit'].sum().nlargest(10)

  # Year-over-year comparison
  df_2023 = df[df['Order_Date'].dt.year == 2023]['Revenue'].sum()
  df_2024 = df[df['Order_Date'].dt.year == 2024]['Revenue'].sum()
  yoy_growth = ((df_2024 - df_2023) / df_2023 * 100)

  ANSWER EXAMPLES:
  - success: "In Q4 2024, Electronics generated $2.3M in revenue across 1,245 orders, showing 15% growth vs Q4 2023. Top product was MacBook Air
  ($450K). The line chart above shows the monthly trend."
  - no_data: "No orders found for 'Electroncs' category. Did you mean 'Electronics'? Available categories: Electronics, Clothing & Apparel, Home &
  Furniture, Accessories."
  - invalid_date: "Could not parse date '2024-31-01'. Please use YYYY-MM-DD format (e.g., '2024-01-31')."

  IMPORTANT:
  - Always include print() statements for logging (e.g., print(f"LOG: Filtered {{len(df)}} -> {{len(filtered)}} rows"))
  - Use .copy() when creating filtered DataFrames to avoid SettingWithCopyWarning
  - Handle datetime operations carefully - ensure Order_Date is datetime type
  - For string matching, use .str.contains() or exact equality, not regex unless needed
  - Use 'ME' instead of deprecated 'M' for month-end frequency in resample()
  - ALWAYS create charts when user asks for visualization keywords

  User request:
  {question}
  """

print("✅ Planning prompt defined!")

def generate_llm_code(
    question: str,
    df: pd.DataFrame,
    model_name: str = "gemini-2.0-flash-exp",
    temperature: float = 0.2,
) -> str:
    """
    Ask Gemini to produce a plan-with-code response.
    Returns the FULL assistant content (including <execute_python> tags).
    """
    # Build schema
    schema_block = build_schema_block(df)

    # Format prompt
    formatted_prompt = PROMPT.format(schema_block=schema_block, question=question)

    # Log prompt length for debugging
    print(f"📏 Prompt length: {len(formatted_prompt):,} characters")

    try:
        # Configure model
        model = genai.GenerativeModel(
            model_name=model_name,
            generation_config={
                "temperature": temperature,
                "top_p": 0.95,
                "top_k": 40,
                "max_output_tokens": 8192,
            },
            safety_settings={
                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
            }
        )

        # Generate response
        print(f"🔄 Calling Gemini model: {model_name}...")
        response = model.generate_content(formatted_prompt)

        # Check for blocking
        if response.prompt_feedback.block_reason:
            error_msg = f"Response blocked: {response.prompt_feedback.block_reason}"
            print(f"🚫 {error_msg}")
            return f"<execute_python>\nSTATUS='error'\nanswer_text='{error_msg}'\n</execute_python>"

        # Check if response has text
        if not response.text:
            # Check candidates
            if response.candidates:
                candidate = response.candidates[0]
                finish_reason = candidate.finish_reason
                safety_ratings = candidate.safety_ratings

                error_msg = f"Empty response. Finish reason: {finish_reason}. Safety ratings: {safety_ratings}"
                print(f"⚠️ {error_msg}")

                # Return fallback code
                return f"""<execute_python>
STATUS = 'error'
answer_text = 'Gemini returned empty response. Finish reason: {finish_reason}. Try rephrasing your question or reducing complexity.'
print('LOG: Empty response from Gemini')
print('LOG: Finish reason: {finish_reason}')
</execute_python>"""
            else:
                error_msg = "No response candidates received"
                print(f"⚠️ {error_msg}")
                return f"<execute_python>\nSTATUS='error'\nanswer_text='{error_msg}'\n</execute_python>"

        print(f"✅ Received response: {len(response.text):,} characters")
        return response.text

    except Exception as e:
        error_msg = f"Error calling Gemini API: {str(e)}"
        print(f"❌ {error_msg}")
        print(f"Full error: {traceback.format_exc()}")

        # Return fallback code
        return f"""<execute_python>
STATUS = 'error'
answer_text = 'API Error: {str(e).replace("'", "")}. Please check your API key and model name.'
print('LOG: API call failed')
print('LOG: Error: {str(e).replace("'", "")}')
</execute_python>"""

print("✅ Code generator function ready!")

def _extract_execute_block(text: str) -> str:
    """
    Extract Python code from various formats.
    Returns fallback error code if no executable code found.
    """
    # Handle None or empty string
    if not text or text.strip() == "":
        # Return fallback code instead of raising error
        return """
STATUS = "error"
answer_text = "The LLM returned an empty response. This may be due to API issues or model limitations. Please try again or rephrase your question."
print("LOG: Empty LLM response received")
"""

    # Try to extract from <execute_python> tags
    match = re.search(r"<execute_python>(.*?)</execute_python>", text, re.DOTALL | re.IGNORECASE)
    if match:
        code = match.group(1).strip()
        if code:
            return code

    # Try to extract from ```python code blocks
    match = re.search(r"```python\n(.*?)\n```", text, re.DOTALL | re.IGNORECASE)
    if match:
        code = match.group(1).strip()
        if code:
            return code

    # Try to extract from ``` code blocks (without language specification)
    match = re.search(r"```\n(.*?)\n```", text, re.DOTALL)
    if match:
        code = match.group(1).strip()
        # Check if it looks like Python code
        if code and any(keyword in code for keyword in ['import ', 'def ', 'class ', 'pd.', 'df[', 'df.', 'print(']):
            return code

    # Check if the entire text looks like Python code
    if any(keyword in text for keyword in ['import pandas', 'import numpy', 'pd.', 'df[', 'df.', 'try:', 'except:']):
        return text.strip()

    # If no code found, return fallback with the text content
    # Escape quotes and limit length
    safe_text = text.replace('"', '\\"').replace("'", "\\'")[:500]

    fallback_code = f'''
# LLM did not generate executable code
STATUS = "error"
answer_text = """The LLM response did not contain executable Python code.

Response preview: {safe_text}...

Please try:
1. Rephrasing your question more explicitly
2. Asking for specific metrics or time ranges
3. Running the query again (API may have had temporary issues)
"""
print("LOG: No executable code found in LLM response")
print(f"LOG: Response length: {len(text)} characters")
print(f"LOG: Response preview: {safe_text[:200]}")
'''
    return fallback_code


def execute_generated_code(
    code_or_content: str,
    df: pd.DataFrame,
    user_request: Optional[str] = None,
) -> Dict[str, Any]:
    """
    Execute LLM-generated code in a controlled namespace.
    Returns execution results including stdout, errors, and answer variables.
    Never raises exceptions - always returns a result dictionary.
    """
    # Extract code (now guaranteed to return something)
    code = _extract_execute_block(code_or_content)

    # Prepare safe execution namespace
    SAFE_GLOBALS = {
        "pd": pd,
        "np": np,
        "datetime": datetime,
        "timedelta": timedelta,
        "plt": plt,
        "sns": sns,
        "get_date_range": get_date_range,
        "get_quarter_data": get_quarter_data,
        "calculate_profit_margin": calculate_profit_margin,
        "get_top_n": get_top_n,
        "detect_outliers": detect_outliers,
        "len": len,  # Add built-in len
        "str": str,  # Add built-in str
    }

    SAFE_LOCALS = {
        "df": df.copy(),  # Work on a copy to prevent mutations
        "user_request": user_request or "",
        "text": code_or_content,  # Make original response available
    }

    # Capture stdout
    stdout_buffer = io.StringIO()
    old_stdout = sys.stdout
    sys.stdout = stdout_buffer

    error_text = None

    try:
        exec(code, SAFE_GLOBALS, SAFE_LOCALS)
    except Exception as e:
        error_text = traceback.format_exc()
        # Set default error values if execution failed
        SAFE_LOCALS["STATUS"] = "error"
        SAFE_LOCALS["answer_text"] = f"Code execution failed: {str(e)}"
    finally:
        sys.stdout = old_stdout

    printed_output = stdout_buffer.getvalue().strip()

    # Extract answer variables set by generated code
    answer_text = SAFE_LOCALS.get("answer_text")
    answer_json = SAFE_LOCALS.get("answer_json")
    answer_df = SAFE_LOCALS.get("answer_df")
    status = SAFE_LOCALS.get("STATUS", "unknown")

    return {
        "code": code,
        "stdout": printed_output,
        "error": error_text,
        "answer_text": answer_text,
        "answer_json": answer_json,
        "answer_df": answer_df,
        "status": status,
    }

print("✅ Code executor function ready!")

def time_series_agent(
    question: str,
    df: pd.DataFrame,
    model_name: str = "gemini-2.0-flash-exp",
    temperature: float = 0.2,
    show_code: bool = True,
    show_logs: bool = True,
) -> Dict[str, Any]:
    """
    End-to-end time series analysis agent.

    Args:
        question: Natural language query
        df: Pandas DataFrame with transaction data
        model_name: Gemini model to use
        temperature: LLM temperature (0.0-1.0)
        show_code: Display generated code
        show_logs: Display execution logs

    Returns:
        Dictionary with generated code, answer, and metadata
    """
    # Display question
    print_html(question, title="📋 User Question")

    # Generate code
    print("\n🤖 Generating analysis plan...")
    try:
        full_content = generate_llm_code(
            question=question,
            df=df,
            model_name=model_name,
            temperature=temperature,
        )
    except Exception as e:
        print(f"❌ Error during code generation: {e}")
        return {
            "question": question,
            "full_response": "",
            "execution": {
                "code": "",
                "stdout": "",
                "error": str(e),
                "answer_text": f"Failed to generate code: {e}",
                "answer_json": None,
                "answer_df": None,
                "status": "error",
            }
        }

    # Check if response is empty
    if not full_content or not full_content.strip():
        print("⚠️ Warning: LLM returned empty response")
        return {
            "question": question,
            "full_response": "",
            "execution": {
                "code": "",
                "stdout": "",
                "error": "Empty LLM response",
                "answer_text": "The LLM returned an empty response. Please try again.",
                "answer_json": None,
                "answer_df": None,
                "status": "error",
            }
        }

    # Display full response (optional)
    if show_code:
        print_html(full_content, title="💻 Generated Plan & Code")

    # Execute code
    print("\n⚙️ Executing analysis...")
    exec_result = execute_generated_code(
        code_or_content=full_content,
        df=df,
        user_request=question,
    )

    # Display logs
    if show_logs and exec_result["stdout"]:
        print_html(exec_result["stdout"], title="📊 Execution Logs")

    # Display errors if any
    if exec_result["error"]:
        print_html(exec_result["error"], title="❌ Execution Error")

    # Display answer
    status_emoji = {
        "success": "✅",
        "no_data": "⚠️",
        "invalid_date": "⚠️",
        "invalid_filter": "⚠️",
        "ambiguous_request": "❓",
        "error": "❌",
    }.get(exec_result["status"], "ℹ️")

    if exec_result["answer_text"]:
        print_html(
            exec_result["answer_text"],
            title=f"{status_emoji} Analysis Result (Status: {exec_result['status']})"
        )

    # Display structured data if available
    if exec_result["answer_df"] is not None:
        print("\n📈 Detailed Results:")
        display(exec_result["answer_df"])

    if exec_result["answer_json"]:
        print("\n📄 Structured Data:")
        print(json.dumps(exec_result["answer_json"], indent=2))

    return {
        "question": question,
        "full_response": full_content,
        "execution": exec_result,
    }

print("✅ Time series agent ready!")

result1 = time_series_agent(
    question="Show me the monthly revenue trend for Electronics category in 2024",
    df=df,
    temperature=0.3,
)

result2 = time_series_agent(
    question="Compare Q4 2023 vs Q4 2024 revenue across all regions",
    df=df,
    temperature=0.3,
)

result1 = time_series_agent(
    question="Show me the monthly revenue trend for Electronics category in 2024",
    df=df,
    temperature=0.3,
)

result3 = time_series_agent(
    question="What is the time range in this dataset? how many months and quarter?",
    df=df,
    temperature=0.3,
)

result3 = time_series_agent(
    question="What are the product categories in this dataset?",
    df=df,
    temperature=0.3,
)

result3 = time_series_agent(
    question="Can you show profit of each product in home & furniture categoreis by querter in line chart?",
    df=df,
    temperature=0.3,
)

result1 = time_series_agent(
    question="Can you list down top 10 most profitable products during dataset period",
    df=df,
    temperature=0.3,
)

result2 = time_series_agent(
    question="Can you show top 10 most frequent buyers during dataset period and the sales they bring",
    df=df,
    temperature=0.3,
)

result2 = time_series_agent(
    question="Can you show scatter plot showing correlation between purchase frequency and purchase value during dataset period",
    df=df,
    temperature=0.3,
)

result3 = time_series_agent(
    question="5 products that have highest declining profit margins between Jaunary 2023 and June 2023?",
    df=df,
    temperature=0.3,
)

result3 = time_series_agent(
    question="Which product category has the highest profit margin during the dataset period? can you rank it in descending order?",
    df=df,
    temperature=0.3,
)

result3 = time_series_agent(
    question="can you show scatter plot showing correlation between profit margin and sales for each product category during dataset period? we want to know whether higher sales value means higher profit",
    df=df,
    temperature=0.3,
)

result3 = time_series_agent(
    question="How has total revenue changed over time?",
    df=df,
    temperature=0.3,
)

result3 = time_series_agent(
    question="What is the trend of total profit and total revenue during dataset period?",
    df=df,
    temperature=0.3,
)

result3 = time_series_agent(
    question="Does profit margin fluctuate seasonally or cyclically throughout the year?",
    df=df,
    temperature=0.3,
)

result3 = time_series_agent(
    question="can you give 10 products that show consistent profit margin during dataset period? what is their range?",
    df=df,
    temperature=0.3,
)

result3 = time_series_agent(
    question="How does average profit per product category evolve over time?",
    df=df,
    temperature=0.3,
)

result3 = time_series_agent(
    question="Are there seasonal patterns in customer purchase behavior by category?",
    df=df,
    temperature=0.3,
)

result3 = time_series_agent(
    question="How has the number of active or repeat customers changed over time?",
    df=df,
    temperature=0.3,
)

result3 = time_series_agent(
    question="can you show top 10 repeat customers by profit in bar chart?",
    df=df,
    temperature=0.3,
)

result3 = time_series_agent(
    question="can you show top 10 repeat customers by frequency? include their purchase value and profit margin in the table?",
    df=df,
    temperature=0.3,
)

result3 = time_series_agent(
    question="can you list down 10 one-time customer in december 2024 that has highest purchase value? include product they bought in the table?",
    df=df,
    temperature=0.3,
)

result3 = time_series_agent(
    question="can you list down 10 one-time customer in december 2024 that bring highest profit? include product they bought in the table?",
    df=df,
    temperature=0.3,
)

result3 = time_series_agent(
    question="How do shifts in customer behavior and category performance combine to impact overall profitability over time?",
    df=df,
    temperature=0.3,
)

result3 = time_series_agent(
    question="can you list down top 10 most frequently purchased products during dataset period? include quantity sold, purchase value and profit margin in the table",
    df=df,
    temperature=0.3,
)

result3 = time_series_agent(
    question="can you list down top 10 product that has highest repeat order during dataset period? include quantity sold, purchase value and profit margin in the table",
    df=df,
    temperature=0.3,
)

result3 = time_series_agent(
    question="can you list down top 5 most frequently purchased customers during dataset period? include product they bought most often, how many they bought, and how much they spend on these items in the table",
    df=df,
    temperature=0.3,
)